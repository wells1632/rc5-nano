
 distributed.net client for ATI FireStream-compatible GPUs
 document revision $Id: readme.stream,v 1.4 2009/12/29 06:04:06 chandleg Exp $

 Welcome to the distributed.net client.

 This document covers information specific to the client for the ATI
 FireStream-capable video card GPU. Refer to other enclosed documentation or
 browse the online FAQ at <http://faq.distributed.net/> for
 non-platform-specific documentation.

    1.0  ATI FireStream specific notes
    2.0  Prerequisites
    3.0  Getting started
    4.0  Troubleshooting and Known issues
         4.1 Multiple GPUs
         4.2 GPU Client priority
         4.3 RC5-72 block sizes

 1.0  ATI FireStream specific notes ------------------------------------

    This client requires ATI FireStream-capable hardware and appropriate
    drivers to be installed.  For a list of GPU hardware that supports
    FireStream, see <http://en.wikipedia.org/wiki/FireStream#Hardware> 

    With this version of the client you no longer need the FireStream drivers
    or the SDK.  If you want them it is an option you can pursue.

    You will need at least do download the ATI Catalyst Drivers for Linux,
    which will install the shared libraries you need and your Kernel Driver.  {Linux}

    Our FireStream clients also only execute crunchers on the GPU.  In order
    to utilize the CPUs on your computer, you will need to download
    and run another instance of the standard client from a separate
    subdirectory.


 2.0  Prerequisites -------------------------------------------------

    On a Linux host there are several requirements that need to be met
    to run the FireStream client.

    1) The FireStream kernel module must be downloaded and built against
       your running kernel's sources.  This driver will be called "fglrx".

       This is contained in the Catalyst Drivers, NOTE: this will replace
       your X/Xorg drivers.

    2) The FireStream kernel module must be loaded.  Once the driver is
       loaded, X/Xorg can be started.

    4) X/Xorg must be running.  Due to some reason which is not obvious 
       to me, the only way to connect to the resources of the card is 
       through a combination of the X/Xorg drivers and the kernel module.

       NOTE: The driver in use also MUST be fglrx from either the Catalyst
             or FireStream Drivers.
       NOTE: The primary interface for X/Xorg MUST be the card you want
             to use as a stream device.  The client doesn't support 
             Crossfire or multi-GPU yet.

 3.0  Getting started ------------------------------------------------
 
    Just unpack/unzip/untar the client in a directory of your choice and 
    fire it up.

    If you have never run the client before, it will initiate the
    menu-driven configuration. Save and quit when done.

    Then, simply restart the client. From that point on it will use the 
    saved configuration.
    
    The configuration options are fairly self-explanatory and can be run
    at any time by starting the client with the '-config' option.
    A list of command line options is available by starting the client 
    with '-help' or '--help'.

    A complete step-by-step guide to running your first client is 
    available at <http://www.distributed.net/docs/tutor_clients.php>

 4.0  Troubleshooting and Known issues ------------------------------

    On Linux platforms, YOU WILL SEE errors when running the 
    client on a text-mode system without X11 (init level 3 not 5).
    As noted in the Prerequisites section X/Xorg MUST be running for
    the client to work properly.  This can be a headless display, but
    it MUST be running with the fglrx kernel and X/Xorg drivers loaded.

    If you are unable to execute the dnetc binary because of a missing
    "libaticalrt.so" or "libaticalcl.so" library, you will need to visit
    the ATI website and download and install a later driver.

    If you have an onboard FireStream compatible card such as a Radeon 
    HD 3200 or HD 3300, and an additional stream-capable card, and you
    are seeing massively slow performance, your onboard video is likely
    the main device in your X/Xorg config.  As stated in the Prerequisites 
    section the primary device must be the card you want to use.  As far
    as I can tell, having a CrossFire setup between those two will also 
    break the functionality of the FireStream setup.  This is currently
    a limitation of the libraries from ATI.
    
    The most simple way to fix this, is to enter the BIOS configuration
    of your motherboard and select something other than "Onboard" or 
    "OnChipVGA" or "OVGA", normally this would be "PCI-E".  

    NOTE: This will effectively disable your onboard video!  This will
          also change the PCI device lists in the X/Xorg detection.
          Your x11.conf or xorg.conf will most likely have to be updated
          to reflect the changes.  BE SURE TO MAKE SURE YOUR SYSTEM DOES
          NOT BOOT DIRECTLY INTO X AFTER YOU MAKE THE BIOS CHANGES.  To 
          find the new device use lspci or try to start X.  X will display
          the device number it doesn't know how to use, and you will be
          able to make your changes.  Once you have made those changes,
          use "startx" to test them.  If that works, you may re-enable
          X on start, and then you will need to reboot your system.  Due
          to a bug in the drivers, if you leave X and try to restart it,
          you will be left with a blank screen.  If you know X is running,
          you can hit: ctrl-backspace then ctrl-alt-del right afterwards.
          This will kill X and issue an init 6.


    If you are having trouble with upgrading the drivers to a newer 
    version , feel free to email: chandleg@distributed.net.   ATI's 
    support is pretty lacking.  BEWARE, I don't check my mail as often
    as I should ;)

  4.1   Multiple GPUs -----------------------------------------------

    The current client code can only select one core for crunching a project.
    In the modern world, this does not work well when multiple GPUs are
    installed in one system. Each GPU can be a different age, model or brand
    with different features. As a result each may require different cores for
    optimal performance, or, even worse, some crunching cores could be
    unsupported due to the differences.

    To list all of the GPUs detected by the client, run "dnetc -gpuinfo".

    By default the client will try to use all of the available GPUs. The first
    detected GPU (GPU0) is used as a reference for auto-selection of the
    crunching cores. All benchmarks and tests will run only on GPU0 by
    default. In many cases, all of the GPUs in a system can run the crunching
    core which is automatically selected for GPU0, and their performance on
    this core is also optimal or close to it. In this case, there is no need
    to change anything. In other cases, it may be beneficial to change the
    default behaviour, which can be done with command-line options or
    configuration parameters.

    To run benchmarks or tests on GPUs other then GPU0, use the device number
    option. On the command line: "-devicenum N", or in the configuration:
    "Performance related options" -> "Run on the selected device number only".
    For example, to benchmark GPU1 (the second GPU detected), run
    "dnetc -devicenum 1 -bench".

    If you need or want to use different parameters for each GPU, you must use
    the device number option. With this option specified, the client will run
    only ONE process and it will run only on the specified device, i.e. you
    must run as many copies of the client as the number of GPUs you want to
    use, each with a unique device number setting. Identification and
    automatic core selection will be done using the GPU specified when using
    the device number option.

    It is possible to run multiple copies of the client from the same
    directory using different command-line options. You can also run each copy
    of the client in its own folder or you can copy the client executable
    under different names in the same folder so it will use different
    configuration files. For example, if you name them as "dnetc_gpu0.exe" and
    "dnetc_gpu1.exe", their configuration files will be automatically named
    "dnetc_gpu0.ini" and "dnetc_gpu1.ini" correspondingly). Windows users may
    need to add "-multiok=1" to command-line options, otherwise multiple
    copies of the client will not be allowed to run. If you are using
    checkpoint files, make sure that each copy of the client is using its own
    private file.

  4.2   GPU Client priority -----------------------------------------

    Some fast GPUs may require a significant amount of CPU power to keep them
    busy. If you are running both GPU and CPU clients, and your real crunch
    rates are significantly less than the benchmarked values, you may feel
    that you need to give more CPU time to the GPU client. There are two ways
    that you can do this. One way is to decrease the number of CPU cores used
    by the CPU client ("-numcpu" option) so that a CPU core is available to be
    used by the GPU client. This is the safest solution. Obviously, the output
    of your CPU client will be decreased. The other way (possibly a better
    solution) is to increase the priority of the GPU client using the priority
    option at runtime ("-priority N" or in the configuration: "Performance
    related options" -> "Priority level to run at"). The default priority
    level is 0 (idle). You can increase it from 0 to 9 until the GPU client
    gets enough CPU time to keep the GPU busy. If you set the priority level
    too high, it may decrease responsiveness of other programs running on your
    computer, so take care when using this option.

  4.3   RC5-72 block sizes ------------------------------------------

    With the speed of modern GPUs, the overhead caused by accessing the buffer
    files and sending updates to the network may become noticeable and reduce
    the overall client performance. By default, GPU clients request larger
    packets than CPU clients, with a size of 64 RC5-72 units. For GPUs which
    are quite fast (1 Gkey/sec or faster), even this packet will only take a
    few minutes to complete. It is possible to increase the packet size in the
    configuration: "Buffer and Buffer Update Options"/"Preferred packet size".
    Similarly, if your GPU is slower and the default packet size takes too
    much time to complete, the packet size can be decreased. We currently
    support packet sizes in the range of 1 - 1024 units. Note that this is the
    preferred value the client software sends to the key server network in a
    request. The server may return a smaller packet if no larger ones are
    available. It is also recommended to minimize the network update frequency;
    the default configuration is usually sufficient. To decrease delays caused
    by network updates, we recommend that you use the distributed.net personal
    proxy software. ( http://www.distributed.net/Download_proxies ) Note that
    if you are using the personal proxy software, you may need to alter the
    proxy configuration to request larger packet sizes as well.
