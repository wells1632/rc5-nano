
 distributed.net client for nVidia CUDA-compatible GPUs
 document revision $Id: readme.cuda,v 1.15 2014/02/23 22:56:01 zebe Exp $

 Welcome to the distributed.net client.

 This document covers information specific to the client for the nVidia
 CUDA-capable video card GPU. Refer to other enclosed documentation or
 browse the online FAQ at <http://faq.distributed.net/> for
 non-platform-specific documentation.

    1.0  Getting started
    2.0  nVidia CUDA specific notes
    3.0  Troubleshooting and known issues
         3.1 Multiple GPUs
         3.2 GPU Client priority
         3.3 RC5-72 block sizes

 1.0  Getting started ------------------------------------------------
 
    Just unpack/unzip/untar the client in a directory of your choice and 
    fire it up.

    If you have never run the client before, it will initiate the
    menu-driven configuration. Save and quit when done.

    Then, simply restart the client. From that point on it will use the 
    saved configuration.
    
    The configuration options are fairly self-explanatory and can be run
    at any time by starting the client with the '-config' option.
    A list of command line options is available by starting the client 
    with '-help' or '--help'.

    A complete step-by-step guide to running your first client is 
    available at <http://www.distributed.net/docs/tutor_clients.php>

 2.0  nVidia CUDA specific notes ------------------------------------

    This client requires nVidia CUDA-capable hardware and appropriate
    drivers to be installed.  For a list of GPU hardware that supports
    CUDA, see <http://en.wikipedia.org/wiki/CUDA#Supported_GPUs>

    When installing the CUDA drivers, be sure to download the version
    matching the client build, e.g. CUDA 5.5, 3.1, 3.0, etc.
    When there are separate CUDA builds available for your platform,
    please use the matching driver version!
    Visit <https://developer.nvidia.com/cuda-downloads>

    It is not neccessary to install the CUDA Toolkit as a copy of the
    CUDA runtime library from CUDA Toolkit is bundled with the client.
    You may have to adjust environment variables so that the library is
    found, see below.

    At the moment, our CUDA clients only provide support for RC5-72.
    Due to the nature of OGR, it is difficult to parallelize in a way
    that can make use of the CUDA architecture.

    Our CUDA clients also only execute crunchers on the GPU.  In order
    to utilize the CPUs on your computer, you will need to download
    and run another instance of the standard client from a separate
    subdirectory.


 3.0  Troubleshooting and known issues ------------------------------

    The required nVidia driver version is 256.xx for use with CUDA 3.1
    and 195.xx for CUDA 3.0. While newer drivers might work, older
    versions definitively won't work.


    On Windows Vista platforms, the CUDA client will not be able to
    access the GPU when run as a Service due to operating system
    limitations.  The current workaround is to run the client
    interactively as a logged-in user instead.


    On Linux platforms, you may see errors when running the CUDA
    client on a text-mode system without X11 (init level 3 not 5).
    This usually occurs because the nVidia module has not been
    loaded or the /dev/nvidiactl control file has not been
    initialized.  To make your RHEL/CentOS system automatically
    prepare these things without starting X11, see
    <http://forums.nvidia.com/lofiversion/index.php?t52629.html>
    Similar solutions will be necessary for other distributions.

    You may also encounter problems on Linux platforms if you try
    to run the CUDA client as a non-root user that does not have
    permission to access the /dev/nvidiactl control file.
    Typically membership to the "video" group is used to manage
    access, so you will need to ensure that your UNIX user is a
    member of it.  If uncertain, view the file permissions of
    the /dev/nvidiactl control file.


    For your convenience a copy of the required CUDA runtime
    library (Linux: libcudart.so.3; Mac OS X: libcudart.dylib;
    Windows: cudart.dll) is bundled with the client. For Linux and
    Mac OS X these libraries are located in the lib/ subdirectory.

    If you are unable to execute the dnetc binary because of a missing
    libcudart.so library, you have to set your LD_LIBRARY_PATH environment
    variable (on Linux) or DYLD_LIBRARY_PATH (on Mac OS X) to include
    the 'lib' subdirectory of the extracted client archive prior to
    running dnetc.


    In systems with dual nVidia cards, you must ensure that SLI is
    turned "off" in the driver panel.  On Vista (but not Windows XP),
    you must connect a second monitor (if you're using a flat panel
    and it has a second input, you can use that) to the second card
    and "Extend" your desktop onto that monitor.  You can then
    disconnect the monitor leaving your desktop "extended."  The
    client should then find all GPUs.

  3.1   Multiple GPUs -----------------------------------------------

    The current client code can only select one core for crunching a project.
    In the modern world, this does not work well when multiple GPUs are
    installed in one system. Each GPU can be a different age, model or brand
    with different features. As a result each may require different cores for
    optimal performance, or, even worse, some crunching cores could be
    unsupported due to the differences.

    To list all of the GPUs detected by the client, run "dnetc -gpuinfo".

    By default the client will try to use all of the available GPUs. The first
    detected GPU (GPU0) is used as a reference for auto-selection of the
    crunching cores. All benchmarks and tests will run only on GPU0 by
    default. In many cases, all of the GPUs in a system can run the crunching
    core which is automatically selected for GPU0, and their performance on
    this core is also optimal or close to it. In this case, there is no need
    to change anything. In other cases, it may be beneficial to change the
    default behaviour, which can be done with command-line options or
    configuration parameters.

    To run benchmarks or tests on GPUs other then GPU0, use the device number
    option. On the command line: "-devicenum N", or in the configuration:
    "Performance related options" -> "Run on the selected device number only".
    For example, to benchmark GPU1 (the second GPU detected), run
    "dnetc -devicenum 1 -bench".

    If you need or want to use different parameters for each GPU, you must use
    the device number option. With this option specified, the client will run
    only ONE process and it will run only on the specified device, i.e. you
    must run as many copies of the client as the number of GPUs you want to
    use, each with a unique device number setting. Identification and
    automatic core selection will be done using the GPU specified when using
    the device number option.

    It is possible to run multiple copies of the client from the same
    directory using different command-line options. You can also run each copy
    of the client in its own folder or you can copy the client executable
    under different names in the same folder so it will use different
    configuration files. For example, if you name them as "dnetc_gpu0.exe" and
    "dnetc_gpu1.exe", their configuration files will be automatically named
    "dnetc_gpu0.ini" and "dnetc_gpu1.ini" correspondingly). Windows users may
    need to add "-multiok=1" to command-line options, otherwise multiple
    copies of the client will not be allowed to run. If you are using
    checkpoint files, make sure that each copy of the client is using its own
    private file.

    CUDA specific note: even if the device number option is specified, the
    client will still query the properties of GPU0 to verify that the CUDA
    drivers are working properly. If this causes any problems, please report
    them to us on http://bugs.distributed.net/ (Bugzilla).

  3.2   GPU Client priority -----------------------------------------

    Some fast GPUs may require a significant amount of CPU power to keep them
    busy. If you are running both GPU and CPU clients, and your real crunch
    rates are significantly less than the benchmarked values, you may feel
    that you need to give more CPU time to the GPU client. There are two ways
    that you can do this. One way is to decrease the number of CPU cores used
    by the CPU client ("-numcpu" option) so that a CPU core is available to be
    used by the GPU client. This is the safest solution. Obviously, the output
    of your CPU client will be decreased. The other way (possibly a better
    solution) is to increase the priority of the GPU client using the priority
    option at runtime ("-priority N" or in the configuration: "Performance
    related options" -> "Priority level to run at"). The default priority
    level is 0 (idle). You can increase it from 0 to 9 until the GPU client
    gets enough CPU time to keep the GPU busy. If you set the priority level
    too high, it may decrease responsiveness of other programs running on your
    computer, so take care when using this option.

  3.3   RC5-72 block sizes ------------------------------------------

    With the speed of modern GPUs, the overhead caused by accessing the buffer
    files and sending updates to the network may become noticeable and reduce
    the overall client performance. By default, GPU clients request larger
    packets than CPU clients, with a size of 64 RC5-72 units. For GPUs which
    are quite fast (1 Gkey/sec or faster), even this packet will only take a
    few minutes to complete. It is possible to increase the packet size in the
    configuration: "Buffer and Buffer Update Options"/"Preferred packet size".
    Similarly, if your GPU is slower and the default packet size takes too
    much time to complete, the packet size can be decreased. We currently
    support packet sizes in the range of 1 - 1024 units. Note that this is the
    preferred value the client software sends to the key server network in a
    request. The server may return a smaller packet if no larger ones are
    available. It is also recommended to minimize the network update frequency;
    the default configuration is usually sufficient. To decrease delays caused
    by network updates, we recommend that you use the distributed.net personal
    proxy software. ( http://www.distributed.net/Download_proxies ) Note that
    if you are using the personal proxy software, you may need to alter the
    proxy configuration to request larger packet sizes as well.
